{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e7e9d8f-8031-49fc-b321-b46e257df6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ROOT = \"/home/vladislav/experiments/texts-similarity\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdeddcfe-f7f1-4d7e-b029-6c10d32a9cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys  \n",
    "sys.path.insert(1, PROJECT_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d6b1f39-4378-4a79-b592-990d8a3aebf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch import Tensor, optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from datasets.siamese.siamese_dataset import SiameseNetworkDataset\n",
    "from determining.random_settings import determine_random\n",
    "from losses.contrastive_loss import ContrastiveLoss\n",
    "from statistic.metrics import Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90862ae3-d4e9-4546-bc29-b255fe66a676",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_args():\n",
    "    parser = argparse.ArgumentParser(\n",
    "    description='PyTorch Siamese network Example')\n",
    "    parser.add_argument(\n",
    "        '--batch-size',\n",
    "        type=int,\n",
    "        default=64,\n",
    "        metavar='N',\n",
    "        help='input batch size for training (default: 64)'\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--test-batch-size',\n",
    "        type=int,\n",
    "        default=1,\n",
    "        metavar='N',\n",
    "        help='input batch size for testing (default: 1)'\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--epochs',\n",
    "        type=int,\n",
    "        default=100,\n",
    "        metavar='N',\n",
    "        help='number of epochs to train (default: 100)'\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--lr',\n",
    "        type=float,\n",
    "        default=0.01,\n",
    "        metavar='LR',\n",
    "        help='learning rate (default: 0.01)'\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--gamma',\n",
    "        type=float,\n",
    "        default=0.001,\n",
    "        metavar='M',\n",
    "        help='Learning rate step gamma (default: 0.001)'\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--no-cuda',\n",
    "        action='store_true',\n",
    "        default=False,\n",
    "        help='disables CUDA training'\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--no-mps',\n",
    "        action='store_true',\n",
    "        default=False,\n",
    "        help='disables macOS GPU training'\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--dry-run',\n",
    "        action='store_true',\n",
    "        default=False,\n",
    "        help='quickly check a single pass'\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--seed',\n",
    "        type=int,\n",
    "        default=134,\n",
    "        metavar='S',\n",
    "        help='random seed (default: 1)'\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--log-interval',\n",
    "        type=int,\n",
    "        default=10,\n",
    "        metavar='N',\n",
    "        help='how many batches to wait before logging training status'\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--save-model',\n",
    "        action='store_true',\n",
    "        default=False,\n",
    "        help='For Saving the current Model'\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--n-splits',\n",
    "        type=int,\n",
    "        default=5,\n",
    "        metavar='N',\n",
    "        help='Number of splits for crossvalidation (default: 5)'\n",
    "    )\n",
    "    \n",
    "    args = parser.parse_args([])\n",
    "    return args\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5a7aef83-b548-4cd1-89d4-ad01144eff14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the Siamese Neural Network\n",
    "class SiameseNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.train_stat: list[Metrics] = list()\n",
    "        self.test_stat: Metrics | None = None\n",
    "\n",
    "        # Setting up the Sequential of CNN Layers\n",
    "        self.cnn1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 96, kernel_size=11, stride=4),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(3, stride=2),\n",
    "\n",
    "            nn.Conv2d(96, 256, kernel_size=5, stride=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "\n",
    "            nn.Conv2d(256, 384, kernel_size=3, stride=1),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        # Setting up the Fully Connected Layers\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(384, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Linear(512, 256)\n",
    "        )\n",
    "\n",
    "    def forward_once(self, x):\n",
    "        # This function will be called for both images\n",
    "        # Its output is used to determine the similarity\n",
    "        output = self.cnn1(x)\n",
    "        output = output.view(output.size()[0], -1)\n",
    "        output = self.fc1(output)\n",
    "        \n",
    "        return output\n",
    "\n",
    "    def forward(self, input1, input2):\n",
    "        # In this function we pass in both images and obtain both vectors\n",
    "        # which are returned\n",
    "        output1 = self.forward_once(input1)\n",
    "        output2 = self.forward_once(input2)\n",
    "        \n",
    "        return output1, output2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5db954f6-e2d2-4541-9cc3-6c15ad39b5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, model: SiameseNetwork, device, train_loader: DataLoader, optimizer, epoch: int) -> None:\n",
    "    model.train()\n",
    "    criterion = ContrastiveLoss()\n",
    "    \n",
    "    loss: Tensor | None = None\n",
    "    \n",
    "    for batch_idx, (images_1, images_2, targets) in enumerate(train_loader, 0):\n",
    "        images_1, images_2, targets = images_1.to(device), images_2.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output1, output2 = model(images_1, images_2)\n",
    "        loss = criterion(output1, output2, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if args.dry_run:\n",
    "            print(f'Epoch: {epoch} \\tLoss: {loss.item()}')\n",
    "            break\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "9c508271-4b3e-45e6-aaeb-d11c74431ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_loader: DataLoader) -> Metrics:\n",
    "    model.eval()\n",
    "    criterion = ContrastiveLoss()\n",
    "\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    loss: Tensor | None = None\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for (images_1, images_2, targets) in test_loader:\n",
    "            images_1, images_2, targets = images_1.to(device), images_2.to(device), targets.to(device)\n",
    "            output1, output2 = model(images_1, images_2)\n",
    "            loss = criterion(output1, output2, targets)\n",
    "            pred = 0 if F.pairwise_distance(output1, output2).item() < 1.1 else 1\n",
    "\n",
    "            y_pred.append(pred)\n",
    "            y_true.extend(targets.detach().cpu().numpy())\n",
    "\n",
    "    return Metrics(y_true=torch.from_numpy(np.array(y_true)), y_pred=torch.from_numpy(np.array(y_pred)), loss=loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "21d511ff-ee45-4e01-a4d7-380844e7ce8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on cuda\n"
     ]
    }
   ],
   "source": [
    "args = get_args()\n",
    "\n",
    "use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "use_mps = not args.no_mps and torch.backends.mps.is_available()\n",
    "\n",
    "determine_random(args.seed)\n",
    "\n",
    "if use_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "elif use_mps:\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "train_kwargs = {'batch_size': args.batch_size}\n",
    "test_kwargs = {'batch_size': args.test_batch_size}\n",
    "\n",
    "if use_cuda:\n",
    "    cuda_kwargs = {'num_workers': 1,\n",
    "                   'pin_memory': True}\n",
    "    train_kwargs.update(cuda_kwargs)\n",
    "    test_kwargs.update(cuda_kwargs)\n",
    "\n",
    "print(f\"Running on {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3ce4041e-62f4-4108-8642-3db5d3093b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformation = transforms.Compose([transforms.Resize((100, 100)), transforms.ToTensor()])\n",
    "\n",
    "total_dataset = SiameseNetworkDataset(\n",
    "    image_folder_dataset=datasets.ImageFolder(\n",
    "        root=f\"{PROJECT_ROOT}/datasets/siamese/data/\"),\n",
    "    transform=transformation)\n",
    "\n",
    "test_metrics = []\n",
    "history = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb32350-1458-4508-9999-3586baf2d932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running split #1\n",
      "SiameseNetwork(\n",
      "  (cnn1): Sequential(\n",
      "    (0): Conv2d(1, 96, kernel_size=(11, 11), stride=(4, 4))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (7): ReLU(inplace=True)\n",
      "  )\n",
      "  (fc1): Sequential(\n",
      "    (0): Linear(in_features=384, out_features=1024, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "  )\n",
      ")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for split_idx, (train_idx, test_idx) in enumerate(KFold(n_splits=args.n_splits, shuffle=True).split(total_dataset)):\n",
    "    print(f\"Running split #{split_idx + 1}\")\n",
    "    train_loader = DataLoader(\n",
    "        total_dataset,\n",
    "        sampler=SubsetRandomSampler(train_idx),\n",
    "        **train_kwargs\n",
    "    )\n",
    "\n",
    "    test_loader = DataLoader(\n",
    "        total_dataset,\n",
    "        sampler=SubsetRandomSampler(test_idx),\n",
    "        **test_kwargs,\n",
    "    )\n",
    "\n",
    "    model = SiameseNetwork().to(device)\n",
    "    print(model)\n",
    "    print()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=args.gamma)\n",
    "\n",
    "    train_metrics = []\n",
    "    for epoch in range(1, args.epochs + 1):\n",
    "        train(args, model, device, train_loader, optimizer, epoch)\n",
    "        train_metrics.append(test(model, device, test_loader))\n",
    "        scheduler.step()\n",
    "    history[split_idx] = train_metrics\n",
    "    test_metrics.append(test(model, device, test_loader))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb895b5-4d56-48b3-b295-8716651d50e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for split_idx in history.keys():\n",
    "    train_metrics = history[split_idx]\n",
    "    X = np.arange(0, len(train_metrics), 1)\n",
    "    \n",
    "    Y1 = [i.precision for i in train_metrics]\n",
    "    Y2 = [i.recall for i in train_metrics]\n",
    "    Y3 = [i.f1 for i in train_metrics]\n",
    "    Y4 = [i.loss for i in train_metrics]\n",
    "    \n",
    "    figure, axis = plt.subplots(2, 2)\n",
    "    \n",
    "    axis[0, 0].plot(X, Y1)\n",
    "    axis[0, 0].set_title(\"Precision\")\n",
    "    \n",
    "    axis[0, 1].plot(X, Y2)\n",
    "    axis[0, 1].set_title(\"Recall\")\n",
    "    \n",
    "    axis[1, 0].plot(X, Y3)\n",
    "    axis[1, 0].set_title(\"F1\")\n",
    "    \n",
    "    axis[1, 1].plot(X, Y4)\n",
    "    axis[1, 1].set_title(\"Loss\")\n",
    "    \n",
    "    test_stat = test_metrics[split_idx]\n",
    "    \n",
    "    print(f\"Split #{split_idx + 1}:\")\n",
    "    print(f'\\tPrecision: {test_stat.precision:.3f}')\n",
    "    print(f'\\tRecall: {test_stat.recall:.3f}')\n",
    "    print(f'\\tF1 Score: {test_stat.f1:.3f}')\n",
    "    figure.tight_layout()\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a07af0-8177-4704-ad85-7a7cb51742ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_precision = 0\n",
    "avg_recall = 0\n",
    "avg_f1 = 0\n",
    "for metric in test_metrics:\n",
    "    avg_precision += metric.precision\n",
    "    avg_recall += metric.recall\n",
    "    avg_f1 += metric.f1\n",
    "print(f'AVG Precision: {avg_precision / len(test_metrics):.3f}')\n",
    "print(f'AVG Recall: {avg_recall / len(test_metrics):.3f}')\n",
    "print(f'AVG F1 Score: {avg_f1 / len(test_metrics):.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b398298-57f8-455b-9fd9-e3066c5a67d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
