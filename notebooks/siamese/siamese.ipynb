{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e7e9d8f-8031-49fc-b321-b46e257df6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ROOT = \"/home/vladislav/experiments/texts-similarity\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdeddcfe-f7f1-4d7e-b029-6c10d32a9cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys  \n",
    "sys.path.insert(1, PROJECT_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d6b1f39-4378-4a79-b592-990d8a3aebf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch import Tensor, optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from datasets.siamese.siamese_dataset import SiameseNetworkDataset\n",
    "from determining.random_settings import determine_random\n",
    "from losses.contrastive_loss import ContrastiveLoss\n",
    "from statistic.metrics import Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a7aef83-b548-4cd1-89d4-ad01144eff14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the Siamese Neural Network\n",
    "class SiameseNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.device = torch.device(\n",
    "            'cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.train_stat: list[Metrics] = list()\n",
    "        self.test_stat: Metrics | None = None\n",
    "\n",
    "        # Setting up the Sequential of CNN Layers\n",
    "        self.cnn1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 96, kernel_size=11, stride=4),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(3, stride=2),\n",
    "\n",
    "            nn.Conv2d(96, 256, kernel_size=5, stride=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "\n",
    "            nn.Conv2d(256, 384, kernel_size=3, stride=1),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        # Setting up the Fully Connected Layers\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(384, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Linear(1024, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Linear(256, 2)\n",
    "        )\n",
    "\n",
    "    def forward_once(self, x):\n",
    "        # This function will be called for both images\n",
    "        # Its output is used to determine the similarity\n",
    "        output = self.cnn1(x)\n",
    "        output = output.view(output.size()[0], -1)\n",
    "        output = self.fc1(output)\n",
    "        return output\n",
    "\n",
    "    def forward(self, input1, input2):\n",
    "        # In this function we pass in both images and obtain both vectors\n",
    "        # which are returned\n",
    "        output1 = self.forward_once(input1)\n",
    "        output2 = self.forward_once(input2)\n",
    "\n",
    "        return output1, output2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5db954f6-e2d2-4541-9cc3-6c15ad39b5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, model: SiameseNetwork, device, train_loader: DataLoader, optimizer, epoch: int) -> None:\n",
    "    model.train()\n",
    "    criterion = ContrastiveLoss()\n",
    "    loss: Tensor | None = None\n",
    "    \n",
    "    for batch_idx, (images_1, images_2, targets) in enumerate(train_loader, 0):\n",
    "        images_1, images_2, targets = images_1.to(device), images_2.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output1, output2 = model(images_1, images_2)\n",
    "        loss = criterion(output1, output2, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if args.dry_run:\n",
    "            print(f'Epoch: {epoch} \\tLoss: {loss.item()}')\n",
    "            break\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c508271-4b3e-45e6-aaeb-d11c74431ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_loader: DataLoader) -> Metrics:\n",
    "    model.eval()\n",
    "\n",
    "    criterion = ContrastiveLoss()\n",
    "\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    loss: Tensor | None = None\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for (images_1, images_2, targets) in test_loader:\n",
    "            images_1, images_2, targets = images_1.to(\n",
    "                device), images_2.to(device), targets.to(device)\n",
    "            output1, output2 = model(images_1, images_2)\n",
    "            # sum up batch loss\n",
    "            loss = criterion(output1, output2, targets)\n",
    "            pred = 0 if F.pairwise_distance(output1, output2).item() < 1.0 else 1\n",
    "\n",
    "            y_pred.append(pred)\n",
    "            y_true.extend(targets.detach().cpu().numpy())\n",
    "\n",
    "    return Metrics(y_true=torch.from_numpy(np.array(y_true)), y_pred=torch.from_numpy(np.array(y_pred)), loss=loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90862ae3-d4e9-4546-bc29-b255fe66a676",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_args():\n",
    "    parser = argparse.ArgumentParser(\n",
    "    description='PyTorch Siamese network Example')\n",
    "    parser.add_argument(\n",
    "        '--batch-size',\n",
    "        type=int,\n",
    "        default=64,\n",
    "        metavar='N',\n",
    "        help='input batch size for training (default: 64)'\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--test-batch-size',\n",
    "        type=int,\n",
    "        default=1,\n",
    "        metavar='N',\n",
    "        help='input batch size for testing (default: 1)'\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--epochs',\n",
    "        type=int,\n",
    "        default=100,\n",
    "        metavar='N',\n",
    "        help='number of epochs to train (default: 100)'\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--lr',\n",
    "        type=float,\n",
    "        default=1.0,\n",
    "        metavar='LR',\n",
    "        help='learning rate (default: 1.0)'\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--gamma',\n",
    "        type=float,\n",
    "        default=0.7,\n",
    "        metavar='M',\n",
    "        help='Learning rate step gamma (default: 0.7)'\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--no-cuda',\n",
    "        action='store_true',\n",
    "        default=False,\n",
    "        help='disables CUDA training'\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--no-mps',\n",
    "        action='store_true',\n",
    "        default=False,\n",
    "        help='disables macOS GPU training'\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--dry-run',\n",
    "        action='store_true',\n",
    "        default=False,\n",
    "        help='quickly check a single pass'\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--seed',\n",
    "        type=int,\n",
    "        default=134,\n",
    "        metavar='S',\n",
    "        help='random seed (default: 1)'\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--log-interval',\n",
    "        type=int,\n",
    "        default=10,\n",
    "        metavar='N',\n",
    "        help='how many batches to wait before logging training status'\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--save-model',\n",
    "        action='store_true',\n",
    "        default=False,\n",
    "        help='For Saving the current Model'\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--n-splits',\n",
    "        type=int,\n",
    "        default=5,\n",
    "        metavar='N',\n",
    "        help='Number of splits for crossvalidation (default: 5)'\n",
    "    )\n",
    "    \n",
    "    args = parser.parse_args([])\n",
    "    return args\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce4041e-62f4-4108-8642-3db5d3093b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on cuda\n",
      "Fold 1\n",
      "-------\n"
     ]
    }
   ],
   "source": [
    "# Training settings\n",
    "args = get_args()\n",
    "\n",
    "use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "use_mps = not args.no_mps and torch.backends.mps.is_available()\n",
    "\n",
    "determine_random(args.seed)\n",
    "\n",
    "if use_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "elif use_mps:\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "train_kwargs = {'batch_size': args.batch_size}\n",
    "test_kwargs = {'batch_size': args.test_batch_size}\n",
    "\n",
    "if use_cuda:\n",
    "    cuda_kwargs = {'num_workers': 1,\n",
    "                   'pin_memory': True}\n",
    "    train_kwargs.update(cuda_kwargs)\n",
    "    test_kwargs.update(cuda_kwargs)\n",
    "\n",
    "print(f\"Running on {device}\")\n",
    "\n",
    "# Resize the images and transform to tensors\n",
    "transformation = transforms.Compose([transforms.Resize((100, 100)), transforms.ToTensor()])\n",
    "\n",
    "total_dataset = SiameseNetworkDataset(\n",
    "    image_folder_dataset=datasets.ImageFolder(\n",
    "        root=f\"{PROJECT_ROOT}/datasets/siamese/data/faces/training/\"),\n",
    "    transform=transformation)\n",
    "\n",
    "test_metrics = []\n",
    "\n",
    "# Initialize the k-fold cross validation\n",
    "kf = KFold(n_splits=args.n_splits, shuffle=True)\n",
    "\n",
    "# Loop through each fold\n",
    "for fold, (train_idx, test_idx) in enumerate(kf.split(total_dataset)):\n",
    "    print(f\"Fold {fold + 1}\")\n",
    "    print(\"-------\")\n",
    "\n",
    "    # Define the data loaders for the current fold\n",
    "    train_loader = DataLoader(\n",
    "        total_dataset,\n",
    "        sampler=SubsetRandomSampler(train_idx),\n",
    "        **train_kwargs\n",
    "    )\n",
    "\n",
    "    test_loader = DataLoader(\n",
    "        total_dataset,\n",
    "        sampler=SubsetRandomSampler(test_idx),\n",
    "        **test_kwargs,\n",
    "    )\n",
    "\n",
    "    model = SiameseNetwork().to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
    "\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=args.gamma)\n",
    "\n",
    "    train_metrics = []\n",
    "\n",
    "    for epoch in range(1, args.epochs + 1):\n",
    "        train(args, model, device, train_loader, optimizer, epoch)\n",
    "        train_metrics.append(test(model, device, test_loader))\n",
    "        scheduler.step()\n",
    "\n",
    "    X = np.arange(0, len(train_metrics), 1)\n",
    "\n",
    "    Y1 = [i.precision for i in train_metrics]\n",
    "    Y2 = [i.recall for i in train_metrics]\n",
    "    Y3 = [i.f1 for i in train_metrics]\n",
    "    Y4 = [i.loss for i in train_metrics]\n",
    "\n",
    "    figure, axis = plt.subplots(2, 2)\n",
    "\n",
    "    axis[0, 0].plot(X, Y1)\n",
    "    axis[0, 0].set_title(\"Precision\")\n",
    "\n",
    "    axis[0, 1].plot(X, Y2)\n",
    "    axis[0, 1].set_title(\"Recall\")\n",
    "\n",
    "    axis[1, 0].plot(X, Y3)\n",
    "    axis[1, 0].set_title(\"F1\")\n",
    "\n",
    "    axis[1, 1].plot(X, Y4)\n",
    "    axis[1, 1].set_title(\"Loss\")\n",
    "\n",
    "    figure.tight_layout()\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "    test_stat = test(model, device, test_loader)\n",
    "\n",
    "    print()\n",
    "    print(f'Precision: {test_stat.precision:.3f}')\n",
    "    print(f'Recall: {test_stat.recall:.3f}')\n",
    "    print(f'F1 Score: {test_stat.f1:.3f}')\n",
    "    test_metrics.append(test_stat)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a07af0-8177-4704-ad85-7a7cb51742ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
